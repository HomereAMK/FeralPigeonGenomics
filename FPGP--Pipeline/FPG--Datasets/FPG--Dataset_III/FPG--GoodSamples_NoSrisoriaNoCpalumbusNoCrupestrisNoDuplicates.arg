	-> angsd version: 0.935-41-ge5f1ed4 (htslib: 1.10.2) build(Jun 15 2021 08:38:07)
	-> /groups/hologenomics/software/angsd/v0.935/angsd -nThreads 2 -ref /groups/hologenomics/pacheco/data/Pigeons/Reference/DanishTumbler_Dovetail_ReRun.fasta -bam /groups/hologenomics/pacheco/data/Pigeons/FPGP/FPGP--Analyses/FPGP--Lists/FPG--GoodSamples_NoSrisoriaNoCpalumbusNoCrupestrisNoDuplicates.list -sites /groups/hologenomics/pacheco/data/Pigeons/Reference/PBGP_FinalRun.EcoT22I_Extended_Merged_RemovedPossibleParalogs-g800--Article--Ultra.pos -rf /groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001 -remove_bads 1 -uniqueOnly 1 -baq 1 -C 50 -minMapQ 30 -minQ 20 -minInd 441 -doCounts 1 -GL 1 -doGlf 2 -doMajorMinor 1 -doMaf 1 -MinMaf 0.004 -SNP_pval 1e-6 -doPost 2 -doGeno 3 -doPlink 2 -geno_minDepth 3 -setMaxDepth 69750 -dumpCounts 2 -postCutoff 0.95 -doHaploCall 1 -out /groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp 
	-> Sun Jun 20 23:09:24 2021
----------------
multiReader.cpp:
	-nLines	50	(Number of lines to read)
	-beagle	(null)	(Beagle Filename (can be .gz))
	-bgen	(null)	(Bgen Filename)
	-vcf-GL	(null)	(vcf Filename (can be bcf compressed or uncompressed))
	-vcf-PL	(null)	(vcf Filename (can be bcf compressed or uncompressed))
	-vcf-GP	(null)	(vcf Filename (can be bcf compressed or uncompressed))(*not used)
	-glf	(null)	(glf Filename (can be .gz))
	-pileup	(null)	(pileup Filename (can be .gz))
	-intName 1	(Assume First column is chr_position)
	-isSim	1	(Simulated data assumes ancestral is A)
	-nInd	0		(Number of individuals)
	-minQ	20	(minimum base quality; only used in pileupreader)
	-fai	(null)	(fai file)
	-minQ	20	(minimum base quality; only used in pileupreader)
----------------
multiReader.cpp:
---------------
parseArgs_bambi.cpp: bam reader:
	-bam/-b		/groups/hologenomics/pacheco/data/Pigeons/FPGP/FPGP--Analyses/FPGP--Lists/FPG--GoodSamples_NoSrisoriaNoCpalumbusNoCrupestrisNoDuplicates.list	(list of BAM/CRAM files)
	-i		/groups/hologenomics/pacheco/data/Pigeons/FPGP/FPGP--Analyses/FPGP--Lists/FPG--GoodSamples_NoSrisoriaNoCpalumbusNoCrupestrisNoDuplicates.list	(Single BAM/CRAM file)
	-r		(null)	Supply a single region in commandline (see examples below)
	-rf		/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001	Supply multiple regions in a file (see examples below)
	-remove_bads	1	Discard 'bad' reads, (flag & 512) 
	-uniqueOnly	1	Discards reads that doesn't map uniquely
	-show		0	Mimic 'samtools mpileup' also supply -ref fasta for printing reference column
	-minMapQ	30	Discard reads with mapping quality below
	-minQ		20	Discard bases with base quality below
	-trim		0	Number of based to discard at both ends of the reads
	-trim		0	Number of based to discard at 5' ends of the reads
	-trim		0	Number of based to discard at 3' ends of the reads
	-only_proper_pairs 1	Only use reads where the mate could be mapped
	-C		50	adjust mapQ for excessive mismatches (as SAMtools), supply -ref
	-baq		1	adjust qscores around indels (1=normal baq 2= extended(as SAMtools)), supply -ref
	-redo-baq		0 (recompute baq, instead of using BQ tag)
	-setQscore	-1	Set qscore to this value, relevant for missing qscores
	-checkBamHeaders 1	Exit if difference in BAM headers
	-doCheck	1	Keep going even if datafile is not suffixed with .bam/.cram
	-downSample	0.000	Downsample to the fraction of original data
	-nReads		50	Number of reads to pop from each BAM/CRAMs
	-minChunkSize	250	Minimum size of chunk sent to analyses
	--ignore-RG	1	(dev only)
	+RG		(null)	Readgroups to include in analysis(can be filename)
	+LB		(null)	Libraries to include in analysis(can be filename)

Examples for region specification:
		chr:		Use entire chromosome: chr
		chr:start-	Use region from start to end of chr
		chr:-stop	Use region from beginning of chromosome: chr to stop
		chr:start-stop	Use region from start to stop from chromosome: chr
		chr:site	Use single site on chromosome: chr
--------------------
[shared.cpp:init()]
	-nThreads	2	Number of threads to use
	-nQueueSize	-1	Maximum number of queud elements
	-howOften	100	How often should the program show progress
--------------
abcFilter.cpp:
	-sites		/groups/hologenomics/pacheco/data/Pigeons/Reference/PBGP_FinalRun.EcoT22I_Extended_Merged_RemovedPossibleParalogs-g800--Article--Ultra.pos	(File containing sites to keep (chr pos))
	-sites		/groups/hologenomics/pacheco/data/Pigeons/Reference/PBGP_FinalRun.EcoT22I_Extended_Merged_RemovedPossibleParalogs-g800--Article--Ultra.pos	(File containing sites to keep (chr regStart regStop))
	-sites		/groups/hologenomics/pacheco/data/Pigeons/Reference/PBGP_FinalRun.EcoT22I_Extended_Merged_RemovedPossibleParalogs-g800--Article--Ultra.pos	(File containing sites to keep (chr pos major minor))
	-sites		/groups/hologenomics/pacheco/data/Pigeons/Reference/PBGP_FinalRun.EcoT22I_Extended_Merged_RemovedPossibleParalogs-g800--Article--Ultra.pos	(File containing sites to keep (chr pos major minor af ac an))
	-minInd		441	Only use site if atleast minInd of samples has data
	-setMinDepthInd	1	Only use site if atleast minInd of samples has this minimum depth 
	-capDepth	-1	Only use the first capDepth bases
	-strict	1	 (experimental)
	1) You can force major/minor by -doMajorMinor 3
	And make sure file contains 4 columns (chr tab pos tab major tab minor)
---------------
abcCounts.cpp:
	-doCounts	1	(Count the number A,C,G,T. All sites, All samples)
	-doEBD	0	(Calculate effective basedepth, this will be output in bcffile, beta)
	-minQfile	(null)	 file with individual quality score thresholds)
	-setMaxDepth	69750	(If total depth is larger then site is removed from analysis.
				 -1 indicates no filtering)
	-setMinDepth	-1	(If total depth is smaller then site is removed from analysis.
				 -1 indicates no filtering)
	-setMaxDepthInd	-1	(If depth persample is larger then individual is removed from analysis (from site).
				 -1 indicates no filtering)
	-setMinDepthInd	-1	(If depth persample is smaller then individual is removed from analysis (from site).
				 -1 indicates no filtering)
	-minInd		441	(Discard site if effective sample size below value.
				 0 indicates no filtering)
	-setMaxDiffObs	0	(Discard sites where we observe to many different alleles.
				 0 indicates no filtering)
Filedumping:
	-doDepth	0	(dump distribution of seqdepth)	.depthSample,.depthGlobal
	  -maxDepth	100	(bin together high depths)
	-doQsDist	0	(dump distribution of qscores)	.qs
	-minQ	20	(minimumQ)
	-dumpCounts	2
	  1: total seqdepth for site	.pos.gz
	  2: seqdepth persample		.pos.gz,.counts.gz
	  3: A,C,G,T sum over samples	.pos.gz,.counts.gz
	  4: A,C,G,T sum every sample	.pos.gz,.counts.gz
	-iCounts	0 (Internal format for dumping binary single chrs,1=simple,2=advanced)
	-qfile	(null)	(Only for -iCounts 2)
	-ffile	(null)	(Only for -iCounts 2)
---------------------
abcGL.cpp:
	-GL=1: 
	1: SAMtools
	2: GATK
	3: SOAPsnp
	4: SYK
	5: phys
	6: Super simple sample an allele type GL. (1.0,0.5,0.0)
	7: outgroup gls
	-trim		0		(zero means no trimming)
	-tmpdir		angsd_tmpdir/	(used by SOAPsnp)
	-errors		(null)		(used by SYK)
	-minInd		441		(0 indicates no filtering)

Filedumping:
	-doGlf	2
	1: binary glf (10 log likes)	.glf.gz
	2: beagle likelihood file	.beagle.gz
	3: binary 3 times likelihood	.glf.gz
	4: text version (10 log likes)	.glf.gz
	5: binary saf files (usefull for realSFS)	.glf.gz

---------------------
abcGL.cpp:
	-GL=1: 
	1: SAMtools
	2: GATK
	3: SOAPsnp
	4: SYK
	5: phys
	6: Super simple sample an allele type GL. (1.0,0.5,0.0)
	7: outgroup gls
	-trim		0		(zero means no trimming)
	-tmpdir		angsd_tmpdir/	(used by SOAPsnp)
	-errors		(null)		(used by SYK)
	-minInd		441		(0 indicates no filtering)

Filedumping:
	-doGlf	2
	1: binary glf (10 log likes)	.glf.gz
	2: beagle likelihood file	.beagle.gz
	3: binary 3 times likelihood	.glf.gz
	4: text version (10 log likes)	.glf.gz
	5: binary saf files (usefull for realSFS)	.glf.gz

	-> doMcall=0
-------------------
abcMajorMinor.cpp:
	-doMajorMinor	1
	1: Infer major and minor from GL
	2: Infer major and minor from allele counts
	3: use major and minor from a file (requires -sites file.txt)
	4: Use reference allele as major (requires -ref)
	5: Use ancestral allele as major (requires -anc)
	6: Use EBD for major and minor (requires read data)
	7: Use EBD for minor (Major is ref) (requires -ref and read data, (similar to SAMtools))
	-rmTrans: remove transitions 0
	-skipTriallelic	0
------------------------
abcFreq.cpp:
-doMaf	1 (Calculate persite frequencies '.mafs.gz')
	1: Frequency (fixed major and minor)
	2: Frequency (fixed major unknown minor)
	4: Frequency from genotype probabilities
	8: AlleleCounts based method (known major minor)
	NB. Filedumping is supressed if value is negative
-doPost	2	(Calculate posterior prob 3xgprob)
	1: Using frequency as prior
	2: Using uniform prior
	3: Using SFS as prior (still in development)
	4: Using reference panel as prior (still in development), requires a site file with chr pos major minor af ac an
Filters:
	-minMaf  	0.004000	(Remove sites with MAF below)
	-SNP_pval	23.928127	(Remove sites with a pvalue larger)
	-rmTriallelic	0.000000	(Remove sites with a pvalue lower)
	-forceMaf	0.000000	(Write .mafs file when running -doAsso (by default does not output .mafs file with -doAsso))
	-skipMissing	1	(Set post to 0.33 if missing (do not use freq as prior))
Extras:
	-ref	/groups/hologenomics/pacheco/data/Pigeons/Reference/DanishTumbler_Dovetail_ReRun.fasta	(Filename for fasta reference)
	-anc	(null)	(Filename for fasta ancestral)
	-eps	0.001000 [Only used for -doMaf &8]
	-beagleProb	0 (Dump beagle style postprobs)
	-indFname	(null) (file containing individual inbreedcoeficients)
	-underFlowProtect	0 (file containing individual inbreedcoeficients)
NB These frequency estimators requires major/minor -doMajorMinor
-----------------
abcCallGenotypes.cpp:

-doGeno	3
	1: write major and minor
	2: write the called genotype encoded as -1,0,1,2, -1=not called
	4: write the called genotype directly: eg AA,AC etc 
	8: write the posterior probability of all possible genotypes
	16: write the posterior probability of called genotype
	32: write the posterior probabilities of the 3 gentypes as binary
	-> A combination of the above can be choosen by summing the values, EG write 0,1,2 types with majorminor as -doGeno 3
	-postCutoff=0.950000 (Only genotype to missing if below this threshold)
	-geno_minDepth=3	(-1 indicates no cutof)
	-geno_maxDepth=-1	(-1 indicates no cutof)
	-geno_minMM=-1.000000	(minimum fraction af major-minor bases)
	-minInd=441	(only keep sites if you call genotypes from this number of individuals)

	NB When writing the posterior the -postCutoff is not used
	NB geno_minDepth requires -doCounts
	NB geno_maxDepth requires -doCounts
------------------------
abcHetPlas.cpp:
	-doHetPlas=0 (Perform hetplasmid analysis)
	-maxIter=100	(Max number of iterations)
	-minLRT=-1.000000
------------------------
abcWritePlink.cpp:
	-doPlink	2
	1: binary fam/bim/bed format (still beta, not really working)
	2: tfam/tped format

	NB This is a wrapper around -doGeno see more information for that option
--------------
abcHaploCall.cpp:
	-doHaploCall	1
	(Sampling strategies)
	 0:	 no haploid calling 
	 1:	 (Sample single base)
	 2:	 (Concensus base)
	-doCounts	1	Must choose -doCount 1
Optional
	-minMinor	0	Minimum observed minor alleles
	-maxMis	-1	Maximum missing bases (per site)
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.arg"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.pos.gz"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.counts.gz"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.beagle.gz"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.mafs.gz"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.geno.gz"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.tfam"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.tped"
		->"/groups/hologenomics/scratch/angsd_pacheco/angsd_26268.0000000001.out_tmp.haplo.gz"

	[ALL done] cpu-time used =  30113.38 sec
	[ALL done] walltime used =  32585.00 sec
